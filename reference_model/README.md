# Reference Model Comparison
As one of the machine learning model test methods, it can be used during the use-case testing in the development process of machine learning based modules.
For the input data whose expected output value is unknown, a reference model that defines the range of output values allowed from the features of the input is used as a pseudo-oracle. By doing tests on any input data, we can ensure consistent reliability for the output of the model.

## Requirement

- Python 3.5.4
- See [reference_model_setup.sh](lib/reference_model_setup.sh)

## Tutorial
* There are 2 ways to use this function: importing as a module and invoking from DeepSaucer.

* When used as a module: [1. Common operation](#1-common-operation) → [2. Direct execution](#2-direct-execution) → [4. Output](#4-output)
* When invoked from DeepSaucer: [1. Common operation](#1-common-operation) → [3. Invoking from DeepSaucer](#3-invoking-from-deepsaucer) → [4. Output](#4-output)

### 1. Common Operation
---
1. **Create the config file**

    * Set coverage function setting information in json format<br>

    ```json
    {
      "rule": "Example file path of the text file describing the reference model: reference_models/RefModColSha-v2.txt",
      "rdg_exe":
      [
        "In the data conversion section, a python file path describing a function to convert software input data into model input data, ex: option_functions/classification_object_color.py",
        "In the data conversion section, a python file path describing a function to convert software input data into model input data, ex: option_functions/classification_object_shape.py"
      ],
      "function_names":
      [
        "In the data conversion section, function names to convert software input data into model input data, ex: get_color",
        "In the data conversion section, function names to convert software input data into model input data, ex: get_shape"
      ],
      "rdg_weight": "Evaluation criteria used for reference model matching test, file path of text file describing error weight, ex: reference_models/evaluation_criteria_1.txt",
      "rdg_output": "File path of a text file describing a variable name used for evaluating a transition condition in a reference model, ex: tables/field_names_3.csv"
    }
    ```

    ex) [lib/configs/config_gtsrb.json](lib/configs/config_gtsrb.json)<br>
    ※ If you use lib/configs/config_gtsrb.jsonin the tutorial, modify `/Any/Path/` to the actual path

1. **Generate GTSRB Test Data**
   1. Download the following 3 items from [German Traffic Sign Benchmarks](http://benchmark.ini.rub.de/?section=gtsrb&subsectio)
      * [German Traffic Signs Training Dataset](http://benchmark.ini.rub.de/Dataset/GTSRB_Final_Training_Images.zip)
      * [German Traffic Signs Test Dataset](http://benchmark.ini.rub.de/Dataset/GTSRB_Final_Test_Images.zip)
      * [German Traffic Signs Test Dataset](http://benchmark.ini.rub.de/Dataset/GTSRB_Final_Test_GT.zip)

   1. Decompress the downloaded files, and place them in the following directory structure.
      ```text
      GTSRB_data
      |-- GT-final_test.csv -> Label information that corresponds to each image of the test dataset
      |-- Final_Test -> Test Dataset
      |   `── Images
      `-- Final_Training -> Training data set, images stored for each labeled folder
          `-- Images
              |-- 00000
              |-- 00001
              |-- ...
              |-- 00041
              `-- 00042
      ```

   1. Execute [`generate_gtsrb.py`](examples/gtsrb/generate_gtsrb.py) taking the path of GTSRB_data
      ```shell
      python generate_gtsrb.py -d /Any/Path/GTSRB_data
      ```
      `test_dataset_3_32_32.h5` and `train_dataset_3_32_32.h5` are generated in the same directory as `generate_gtsrb.py`

      How to Use the Generated dataset
      ```python
      from keras.utils import HDF5Matrix

      path = "input_data/test_dataset_3_32_32.h5"

      # Images for 'images'
      images = HDF5Matrix(path, "images")[:]

      # Labels corresponding to the images for 'labels'
      labels = HDF5Matrix(path, "labels")[:]
      print(images.shape)
      # Out[13]: (12630, 3, 32, 32)
      print(labels.shape)
      # Out[14]: (12630, 43)
      ```

### 2. Direct Execution
---
For direct execution, execute by giving 3 parameters to the main function as follows
```python
main(model, dataset, config_path)
```
| Parameters | Type | Description |
| --- | --- | --- |
| model | Model | Model Generated by Keras |
| dataset | ndarray | Dataset used for Test |
| conf_path | String | Config File Path used for Test |

```python
from lib.model import model_load
from lib.dataset import data_create
from lib.ref_model_verification import main

# Load model
model = model_load('/path/to/model_file.h5 or model_file.hdf5')

# Load dataset
dataset = data_create('/path/to/dataset.h5 or dataset.hdf5')

# Config File
config_path = '/path/to/config.json'

main(model, dataset, config_path)
```

Practical Example using GTSRB material: [examples/gtsrb/run_gtsrb.py](examples/gtsrb/run_gtsrb.py)

### 3. Invoking from DeepSaucer
---
* Tutorial using GTSRB

Execute from?DeepSaucer?assuming the following directory structure
```text
Any Directory
|-- deep_saucer_core
|   |-- downloaded_data
|   |   |-- test_dataset_3_32_32.h5
|   |   `-- vggnet_model_acc_0.69.hdf5
|   `-- gtsrb
|       |-- data
|       |   `-- dataset_ref_model.py
|       `-- model
|           `-- model_ref_model.py
`-- reference_model
    `-- lib
        |-- reference_model_setup.sh
        |-- dataset.py
        |-- model.py
        `-- ref_model_verification.py
```
**※ Placing test data created by common operation in `deep_saucer_core/downloaded_data`**

1. Start `DeepSaucer`
1. Select `File` - `Env Setup Script`
    1. Select [lib/reference_model_setup.sh](lib/reference_model_setup.sh)
1. Select `File` - `Dataset Load Script`
   1. Select `deep_saucer_core/gtsrb/data/dataset_ref_model.py`
   1. Select the `Env Setup Script` selected above
1. Select `File` - `Model Load Script`
   1. Select `deep_saucer_core/gtsrb/model/model_ref_model.py`
   1. Select the `Env Setup Script` selected above
1. Select `File` - `Verification Script`
   1. Select [lib/ref_model_verification.py](lib/ref_model_verification.py)
   1. Select the `Env Setup Script` selected above
1. Select the 3 scripts (`Dataset Load`, `Model Load`, and `Verification`) selected above on DeepSaucer
   1. Select `Run` - `Run Test Function`
   1. Select`Next`
   1. Press `Select`, and select [lib/configs/config_gtsrb.json](lib/configs/config_gtsrb.json)
   1. Verification starts with `Run`

### 4. Output
---
The `total number of test cases`, the `number of Inconsistent test cases`, and the `correct answer rate` are displayed in the standard output.
```text
---------------------------------------------
The number of test cases:12630
Inconsistent test cases:244
Success rate:0.98
---------------------------------------------
```

Also, output an HTML file that summarizes the images of the test cases that became `Inconsistent`, results predicted by DNN, `allowable output value range` obtained from the reference model, and a link of the example where the results were the same as the DNN prediction for `Success`

## Used Sign Label Name List
```text
  0: "Speed Limit (20)",
  1: "Speed Limit (30)",
  2: "Speed Limit (50)",
  3: "Speed Limit (60)",
  4: "Speed Limit (70)",
  5: "Speed Limit (80)",
  6: "Limit End (80)",
  7: "Speed Limit (100)",
  8: "Speed Limit (120)",
  9: "No Overtaking",
  10: "No Overtaking by 3.5t and Larger Vehicles",
  11: "Temporary Priority",
  12: "Priority Road",
  13: "Priority Road Ahead- Slow Down",
  14: "Stop",
  15: "Vehicle Passage Prohibited",
  16: "Passage of Vehicles with Loading Capacity 3.5t or More Prohibited",
  17: "No Entry",
  18: "Danger",
  19: "Left Curve Ahead",
  20: "Right Curve Ahead",
  21: "Continuous Curves Ahead, Starting with Left Curve",
  22: "Bump Ahead",
  23: "Caution Slippery",
  24: "Right Lane Ends",
  25: "Construction Site",
  26: "Traffic Light Ahead",
  27: "Caution for Pedestrians",
  28: "Caution for Children Crossing",
  29: "Caution for Bicycles",
  30: "Caution for Freezing",
  31: "Caution for Animal Crossing",
  32: "Limit Ends",
  33: "Designated Direction Only (Right Turn Ahead)",
  34: "Designated Direction Only (Left Turn Ahead)",
  35: "Designated Direction Only (Straight Ahead)",
  36: "Designated Direction Only (Straight or Right Turn Ahead)",
  37: "Designated Direction Only (Straight or Left Turn Ahead)",
  38: "Passage Instructions (Right Side)",
  39: "Passage Instructions (Left Side)",
  40: "Roundabout",
  41: "Limit End (No Overtaking)",
  42: "Limit End (No Overtaking by3.5t and Larger Vehicles)"
```
